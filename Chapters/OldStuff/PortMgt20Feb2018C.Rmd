#Portfolio Management including Reinsurance {#C:PortMgt}


*Chapter preview*. Define $S$ to be (random) obligations that arise from a collection (portfolio) of insurance contracts

-   We are particularly interested in probabilities of large outcomes
    and so formalize the notion of a heavy-tail distribution in Section \@ref(S:Tails).

-   How much in assets does an insurer need to retain to meet
    obligations arising from the random $S$? A study of risk measures in Section \@ref(S:RiskMeasure)
    helps to address this question

-   As with policyholders, insurers also seek mechanisms in order to
    spread risks. A company that sells insurance to an insurance company
    is known as a reinsurer, studied in Section \@ref(S:Reinsurance).

##Tails of Distributions {#S:Tails}

In 1998 freezing rains fell on eastern Ontario, south-western Quebec and lasted for six days. The event doubled the amount of precipitation in the area experienced in any prior ice storm, and resulted in a catastrophe that produced excess of 840,000 cases of insurance claims. This number is 20% more than that of the claims caused by the Hurricane Andrew - one of the largest natural disasters in the history of North America. After all, the catastrophe caused approximately 1.44 billion Canadian dollars insurance settlements which is the highest loss burden in the history of Canada (Lecomte et al., 1998).  More examples of similar catastrophic events that caused extremal insurance losses are Hurricanes Harvey and Sandy, the 2011 Japanese earthquake and tsunami, and so forth.

In the context of insurance, a few heavy losses hitting a portfolio and then converting into claims usually represent the greatest part of the indemnities paid by insurance companies. The aforementioned losses, also called `extremes', are quantitatively modelled by the tails of the associated probability distributions.  From the quantitative modelling standpoint, relying on probabilistic models with improper tails is of course daunting.  For instance, periods of financial stress may appear with higher frequency than the actuaries expect, and insurance losses may occur with worse severity. Therefore, studying the probabilistic behavior in the tail portion of actuarial models is of utmost importance in the modern framework of quantitative risk management. For this reason, this section is devoted to the introduction of a few mathematical notions that characterize the tail weight of random variables (r.v.'s). The applications of these notions will benefit us in the construction and selection of appropriate models with desired mathematical properties in the tail portion, that are suitable for a given task.

Formally, define $X$ to be the (random) obligations that arise from a collection (portfolio) of insurance contracts.  We are particularly interested in studying the right tail of the distribution of $X$. Speaking plainly, a r.v. is said to be heavier-tailed if higher probabilities are assigned to larger values.  Unwelcome outcomes are more likely to occur for an insurance portfolio that is described by a loss r.v. possessing heavier (right) tail.  Tail weight can be an absolute or a relative concept.  Specifically, for the former, we may consider a r.v. to be heavy-tailed if certain mathematical properties of the probability distribution are met.  For the latter, we can say the tail of one distribution is heavier than the other if some tail measures are larger. 

In the statistics and probability literature, there are several quantitative approaches have been proposed to compare and classify tail weight. Among most of these approaches, the survival functions serve as the building block.  In what follows, we are going to introduce two simple yet useful tail classification methods, in which the basic idea is to study the quantities that are closely related to the survival function of $X$.   

####Classification Based on Moments

One possible way of classifying the tail weight of distribution is by assessing the existence of raw moments.  Since our major interest lies in the right tails of distributions, we henceforth assume the obligation/loss r.v. $X$ to be positive. At the outset, let us recall that the $k-$th raw moment of $X$, for $k\in\mathcal{R}_+$, can be computed via
$$\begin{aligned}
    \mu_k^{'} &= k \int_0^{\infty} x^{k-1} S(x) dx, \\
    \end{aligned}$$
where $S(\cdot)$ denotes the survival function of $X$.  It is a simple matter to see that the existence of the raw moments depends on the asymptotic behavior of the survival function at infinity.  Namely, the faster the survival function decays to zero, the higher the order of finite moment the associated r.v. possesses. Hence the maximal order of finite moment, denoted by $k^{\ast}:=\sup\{k\in \mathcal{R}_+|\mu_k^{'}<\infty \}$, can be considered as an indicator of tail weight. This observation leads us to moment-based tail weight classification, which is defined formally next.

**Definition 1.**  For a positive loss random variable $X$, if all the positive raw moments exist, namely the maximal order of finite moment $k^{\ast}=\infty$, then $X$ is said to be light-tailed based on the moment-method. If the $k^{\ast}=a \in (0,\infty)$, then $X$ is said to be heavy-tailed based on the moment-method. Moreover, for two positive loss random variables $X_1$ and $X_2$ with maximal orders of moment $k^{'}_1$ and $k^{'}_2$ respectively, we say $X_1$ has a heavier (right) tail than  $X_2$ if $k^{\ast}_1\leq k^{\ast}_2$.

It is noteworthy that the first part of the aforementioned definition is an absolute concept of tail weight, while the second part is a relative concept that compares the weight of (right) tails between two distributions.  Next, we are going to present a few examples that illustrate the applications of the moment-based method.  Some of these examples are borrowed from Klugman et al., 2012.

**Example 1.**  Let $X\sim Gamma(\alpha,\theta)$, with $\alpha>0$ and $\theta>0$, then for all $k\in \mathcal{R}_+$,
$$\begin{aligned}
    \mu_k^{'} &= \int_0^{\infty} x^k \frac{x^{\alpha-1} e^{-x/\theta}}{\Gamma(\alpha) \theta^{\alpha}} dx \\
    &= \int_0^{\infty} (y\theta)^k  \frac{(y\theta)^{\alpha-1} e^{-y}}{\Gamma(\alpha) \theta^{\alpha}} \theta dy \\
    &= \frac{\theta^k}{\Gamma(\alpha)} \Gamma(\alpha+k) < \infty.\end{aligned}$$

Since all the positive moments exist, i.e., $k^{\ast}=\infty$, in accordance with the moment-based classification method in Definition 1, the gamma distribution is light-tailed.

**Example 2.**  Let $X\sim Weibull(\theta,\tau)$, with $\theta>0$ and $\tau>0$, then for all $k\in \mathcal{R}_+$,
$$\begin{aligned}
    \mu_k^{'} &= \int_0^{\infty} x^k \frac{\tau x^{\tau-1} }{\theta^{\tau}} e^{-(x/\theta)^{\tau}}dx \\
    &= \int_0^{\infty}  \frac{ y^{k/\tau} }{\theta^{\tau}} e^{-y/\theta^{\tau}}dy \\
    &= \theta^{k} \Gamma(1+k/\tau) < \infty.\end{aligned}$$

Again, due to the existence of all the positive moments, the Weibull distribution is light-tailed.

We notice in passing that the gamma and Weibull distributions have been used quite intensively in actuarial practice nowadays.  Applications of these two distributions are vast which include, but are not limited to, insurance claim severity modelling, solvency assessment, loss reserving, aggregate risk approximation, reliability engineering and failure analysis.   We have thus far seem two examples of using the moment-based method to analyze light-tailed distributions.  We document a heavy-tailed example in what follows. 

**Example 3.**  Let $X\sim Pareto(\alpha,\theta)$, with $\alpha>0$ and $\theta>0$, then for $k\in \mathcal{R}_+$
$$\begin{aligned}
    \mu_k^{'} &= \int_0^{\infty} x^k \frac{\alpha \theta^{\alpha}}{(x+\theta)^{\alpha+1}} dx \\
    &= \alpha \theta^{\alpha} \int_{\theta}^{\infty} (y-\theta)^k {y^{-(\alpha+1)}} dy.\end{aligned}$$

Consider a similar integration: 
$$\begin{aligned}
  g_k:=\int_{\theta}^{\infty} {y^{k-\alpha-1}} dy=\left\{
  \begin{array}{ll}
    <\infty, & \hbox{for } k<\alpha\\
    =\infty, & \hbox{for } k\geq \alpha
  \end{array}
\right. .\end{aligned}$$
Meanwhile, 
$$\lim_{y\rightarrow \infty} \frac{(y-\theta)^k {y^{-(\alpha+1)}}}{y^{k-\alpha-1}}=\lim_{y\rightarrow \infty}
(1-\theta/y)^{k}=1.$$
Application of the limit comparison theorem for improper integrals yields $\mu_k^{'}$ is finite if and only if $g_k$ is finite. Hence we can conclude that the raw moments of Pareto r.v.'s exist only up to $k<\alpha$, i.e., $k^{\ast}=\alpha$, and thus the distribution is heavy-tailed.  What is more, the maximal order of finite moments depends only on the shape parameter $\alpha$ and it is an increasing function of $\alpha$.  In other words, based on the moments method, the tail weight of the Pareto r.v.'s is solely manipulated by $\alpha$ --  the smaller the value of $\alpha$, the heavier the tail weight becomes.  Since $k^{\ast}<\infty$, the tail of Pareto distribution is heavier than those of the gamma and Weibull distributions.

We are going to conclude this current section by an open discussion on the limitations of the moment-based method.  Despite its simple implementation and intuitive interpretation, there are certain circumstances in which the application of the moment-based method is not suitable. First, for more complicated probabilistic models, the $k$-th raw moment may not be straightforward to derive and/or the identification of the maximal order of finite moment can be very challenging.  Second, the moment-based method does not well comply with main body of the well established heavy tail theory in literature.  Specifically, the existence of moment generating functions (MGF's) is arguably the most popular method for classifying heavy tail verse light tail within the community of academic actuaries.  However, for some r.v's such as the log normal r.v.'s, their MGF's do not exist even that all the positive moments are finite.  In these cases, applications of the moment-based and the
MFG-based methods can lead to different tail weight assessment.  Third, when we need to compare the tail weight between two light-tailed distributions both having all positive moments exist, the moment-based method is no longer informative. 


####Comparison Based on Limiting Tail Behavior

In order to resolve the shortfalls of the moment-based method discussed in the previous section, an alternative approach for comparing tail weight is to directly study the limiting behavior of the survival functions.  

**Definition 2.** For two r.v.'s $X$ and $Y$, and let 
$$
\gamma:=\lim_{t\rightarrow \infty}\frac{S_X(t)}{S_Y(t)}.
$$
We say that 

- $X$ has a heavier right tail than $Y$ if $\gamma=\infty$;
- $X$ and $Y$ are proportionally equivalent in the right tail, if $\gamma =c\in \mathcal{R}_+$;
- $X$ has a lighter right tail than $Y$ if $\gamma=0$.

**Example 4.** Let $X\sim Pareto(\alpha, \theta)$ and $Y\sim Weibull(\tau, \theta)$, for $\alpha>0$, $\tau>0$, and $\theta>0$, we have
$$\begin{aligned}
    \lim_{t\rightarrow \infty}\frac{S_X(t)}{S_Y(t)} &= \lim_{t\rightarrow \infty}\frac{(1+t/\theta)^{-\alpha}}{\exp\{-(t/\theta)^{\tau}\}} \\
    &= \lim_{t\rightarrow \infty}\frac{\exp\{t/\theta^{\tau} \}}{(1+t^{1/\tau}/\theta)^{\alpha}} \\
    &= \lim_{t\rightarrow \infty}\frac{\sum_{i=0}^{\infty}\left(\frac{t}{\theta^{\tau}}\right)^{i}/i!}{(1+t^{1/\tau}/\theta)^{\alpha}}\\
    &= \lim_{t\rightarrow \infty} \sum_{i=0}^{\infty} \left(t^{-i/\alpha}+\frac{t^{(1/\tau-i/\alpha)}}{\theta} \right)^{-\alpha}/\theta^{\tau i}i!\\
    &= \infty.
    \end{aligned}$$
Therefore, the Pareto distribution has a heavier tail than the Weibull distribution.  One may also realize that exponentials go to infinity faster than polynomials, thus the aforementioned limit must be infinite.  For some distributions, the survival functions do not admit explicite expressions.  In such cases, we may find the following alternative formula useful:
$$\begin{aligned}
    \lim_{t\to \infty} \frac{S_X(t)}{S_Y(t)} &= \lim_{t \to \infty} \frac{S_X^{'}(t)}{S_Y^{'}(t)} \\
    &= \lim_{t \to \infty} \frac{-f_X(t)}{-f_Y(t)} = \lim_{t\to \infty} \frac{f_X(t)}{f_Y(t)}.\end{aligned}$$
given that the density functions exist.  


**Example 5.** Let $X\sim Pareto(\alpha, \theta)$ and $Y\sim Gamma(\alpha, \theta)$, for $\alpha>0$ and $\theta>0$, we have
$$\begin{aligned}
    \lim_{t\to \infty} \frac{f_{X}(t)}{f_{Y}(t)} &= \lim_{t \to \infty} \frac{\alpha \theta^{\alpha} (t+ \theta)^{-\alpha-1}}{t^{\tau-1} e^{-t/\lambda} \lambda^{-\tau} \Gamma(\tau)^{-1}} \\
    &= c \lim_{t\to \infty} \frac{e^{t/\lambda}}{(t+\theta)^{\alpha+1} t^{\tau-1}} \\
    &= \infty,\end{aligned}$$
as exponentials go to infinity faster than polynomials.


##Measures of Risk {#S:RiskMeasure}


-   A **risk measure** is a mapping from the r.v. representing the loss
    associated with the risks to the real line.

-   A risk measure gives a single number that is intended to quantify
    the risk.

    -   For example, the standard deviation is a risk measure.

-   Notation: $\rho(X)$.

-   We briefly mention:

    -   **VaR**: Value at Risk;

    -   **TVaR**: Tail Value at Risk.

####Value at Risk

-   Say $F_X(x)$ represents the cdf of outcomes over a fixed period of
    time, e.g. one year, of a portfolio of risks.

-   We consider positive values of $X$ as losses.

-   **Definition 3.11**: let $X$ denote a loss r.v., then the
    **Value-at-Risk** of $X$ at the $100p\%$ level, denoted $VaR_p(X)$
    or $\pi_p$, is the $100p$ percentile (or quantile) of the
    distribution of $X$.

-   E.g. for continuous distributions we have $$\begin{aligned}
    P(X> \pi_p) &= 1-p.\end{aligned}$$


-   VaR has become the standard risk measure used to evaluate exposure
    to risk.

-   **VaR** is the **amount of capital** required to ensure, with a
    **high degree of certainty**, that the **enterprise does not become
    technically insolvent**.

-   Which degree of certainty?

    -   95$\%$?

    -   in Solvency II $99.5\%$ (or: ruin probability of 1 in 200).


-   **VaR is not subadditive**.

    -   Subadditivity of a risk measure $\rho(.)$ requires
        $$\begin{aligned}
        \rho(X+Y) \leq \rho(X)+\rho(Y).\end{aligned}$$

    -   Intuition behind subadditivity: combining risks is less riskier
        than holding them separately.

-   **Example:** let $X$ and $Y$ be i.i.d. r.v.’s which are
    $\text{Bern}(0.02)$ distributed.

    -   Then, $P(X\leq 0) = 0.98$ and $P(Y\leq 0)=0.98$. Thus,
        $F_X^{-1}(0.975)=F_Y^{-1}(0.975)=0$.

    -   For the sum, $X+Y$, we have $P[X+Y=0]=0.98 \cdot 0.98=0.9604$.
        Thus, $F_{X+Y}^{-1}(0.975)>0$.

    -   VaR is not subadditive, since $\text{VaR}(X+Y)$ in this case is
        larger than $\text{VaR}(X)+\text{VaR}(Y)$.


-   Another **drawback of VaR**:

    -   it is a single quantile risk measure of a predetermined level
        $p$;

    -   no information about the thickness of the upper tail of the
        distribution function from $\text{VaR}_p$ on;

    -   whereas stakeholders are interested in both frequency and
        severity of default.

-   Therefore: study other risk measures, e.g. **Tail Value at
    Risk** (TVaR).


####Tail Value at Risk

-   **Definition 3.12:** let $X$ denote a loss r.v., then the Tail Value
    at Risk of $X$ at the $100p\%$ security level, $\text{TVaR}(p)$, is
    the **expected loss** **given that the loss exceeds the $100p$
    percentile** (or: quantile) of the distribution of $X$.

-   We have (assume continuous distribution) $$\begin{aligned}
    \text{TVaR}_p(X) &= E(X|X>\pi_p) \\
    &= \frac{\int_{\pi_p}^{\infty} x\cdot f(x) dx}{1-F(\pi_p)}.\end{aligned}$$

-   We can rewrite this as **the usual definition of TVaR**
    $$\begin{aligned}
    \text{TVaR}_p(X) &= \frac{\int_{\pi_p}^{\infty} x dF_X(x)}{1-p} \\
    &= \frac{\int_p^1 \text{VaR}_u(X) du}{1-p},\end{aligned}$$ using
    the substitution $F_X(x) = u$ and thus $x=F_X^{-1}(u)$.


-   From the definition $$\begin{aligned}
    \text{TVaR}_p(X) &= \frac{\int_p^1 \text{VaR}_u(X) du}{1-p},\end{aligned}$$
    we understand

    -   TVaR is the **arithmetic average** of the quantiles of $X$, from
        level $p$ on;

    -   TVaR is averaging high level VaR;

    -   TVaR **tells us much more about the tail** of the distribution
        than does VaR alone.


-   Finally, TVaR can also be written as $$\begin{aligned}
    \text{TVaR}_p(X) &= E(X|X>\pi_p) \\
    &= \frac{\int_{\pi_p}^{\infty} x f(x)dx}{1-p} \\
    &= \pi_p + \frac{\int_{\pi_p}^{\infty} (x-\pi_p) f(x) dx}{1-p} \\
    &= \text{VaR}_p(X) + e(\pi_p),\end{aligned}$$ with $e(\pi_p)$ the
    mean excess loss function evaluated at the $100p$th percentile.


-   We can understand these connections as follows. (Assume
    continuous r.v.'s)

-   The relation $$\begin{aligned}
    \text{CTE}_p(X) &= \text{TVaR}_{F_X(\pi_p)}(X),\end{aligned}$$ then
    follows immediately by combining the other two expressions.


-   TVaR is a coherent risk measure, see e.g. [Foundations of Risk
    Measurement](http://onderwijsaanbod.kuleuven.be/syllabi/e/D0R57BE.htm#activetab=doelstellingen_idp1406608) course.

-   Thus, $\text{TVaR}(X+Y) \leq \text{TVaR}(X)+\text{TVaR}(Y)$.

-   When using this risk measure, we never encounter a situation where
    combining risks is viewed as being riskier than keeping
    them separate.


-   **KPW Example 3.18** *(Tail comparisons)* Consider three loss
    distributions for an insurance company. Losses for the next year are
    estimated to be on average 100 million with standard deviation
    223.607 million. You are interested in finding high quantiles of the
    distribution of losses. Using the normal, Pareto, and Weibull
    distributions, obtain the VaR at the 90%, 99%, and 99.99%
    security levels.

-   **Solution**

-   Normal distribution has a lighter tail than the others, and thus
    smaller quantiles.

-   Pareto and Weibull with $\tau<1$ have heavy tails, and thus
    relatively larger extreme quantiles.




-   **Example 3.18** *(Tail comparisons)* Consider three loss
    distributions for an insurance company. Losses for the next year are
    estimated to be on average 100 million with standard deviation
    223.607 million. You are interested in finding high quantiles of the
    distribution of losses. Using the normal, Pareto, and Weibull
    distributions, obtain the VaR at the 99%, 99.9%, and 99.99%
    security levels.

        > qnorm(c(0.9,0.99,0.999),mu,sigma)
        [1] 386.5639 620.1877 790.9976
        > qpareto(c(0.9,0.99,0.999),alpha,s)
        [1]  226.7830  796.4362 2227.3411
        > qweibull(c(0.9,0.99,0.999),tau,theta)
        [1]  265.0949 1060.3796 2385.8541


-   We learn from Example 3.18 that results vary widely depending on the
    choice of distribution.

-   Thus, the selection of an **appropriate loss model** is
    highly important.

-   To obtain numerical values of VaR or TVaR:

    -   estimate from the data directly;

    -   or use distributional formulas, and plug in parameter estimates.


-   When estimating VaR directly from the data:

    -   use R to get quantile from the empirical distribution;

    -   R has 9 ways to estimate a VaR at level $p$ from a sample of
        size $n$, differing in the way the interpolation between order
        statistics close to $np$ .

-   When estimating TVaR directly from the data:

    -   take average of all observations that exceed the threshold
        (i.e.$\pi_p$);

-   **Caution:** we need a large number of observations (and a large
    number of observations $> \pi_p$) in order to get
    reliable estimates.

-   When not may observations in excess of the threshold are available:

    -   construct a loss model;

    -   calculate values of VaR and TVaR directly from the
        fitted distribution.


-   For example $$\begin{aligned}
  \text{TVaR}_p(X) &= E(X|X>\pi_p) \\
    &= \pi_p + \frac{\int_{\pi_p}^{\infty} (x-\pi_p) f(x) dx}{1-p} \\
    &= \pi_p + \frac{\int_{-\infty}^{\infty} (x-\pi_p) f(x) dx -\int_{-\infty}^{\pi_p} (x-\pi_p) f(x) dx }{1-p} \\
    &= \pi_p + \frac{E(X)-\int_{-\infty}^{\pi_p} xf(x) dx -\pi_p (1-F(\pi_p))}{1-p} \\
    &= \pi_p + \frac{E(X) - E[\min{(X,\pi_p)}]}{1-p} = \pi_p + \frac{E(X)-E(X \wedge \pi_p)}{1-p},\end{aligned}$$
    see Appendix A for those expressions.

##Reinsurance {#S:Reinsurance}

Recall that *reinsurance* is simply insurance purchased by an insurer. Insurance purchased by non-insurers is sometimes known as *primary* insurance to distinguish it from reinsurance. Reinsurance differs from personal insurance purchased by individuals, such as auto and homeowners insurance, in contract flexibility. Like insurance purchased by major corporations, reinsurance programs are generally tailored more closely to the
buyer. For contrast, in personal insurance buyers typically cannot negotiate on the contract terms although they may have a variety of different options (contracts) from which to choose.

The two broad types are *proportional* and *non-proportional* reinsurance. A proportional reinsurance contract is an agreement between a reinsurer and a *ceding* company (also known as the *reinsured*) in which the reinsurer assumes a given percent of losses and premium. A reinsurance contract is also known as a *treaty*. Non-proportional agreements are simply everything else. As examples of non-proportional agreements, this chapter focuses on *stop-loss* and *excess of loss* contracts. For all types of agreements, we split the total risk $S$ into the portion taken on by the reinsurer, $Y_{reinsurer}$, and that retained by the insurer, $Y_{insurer}$, that is, $S= Y_{insurer}+Y_{reinsurer}$.

The mathematical structure of a basic reinsurance treaty is the same as the coverage modifications of personal insurance introduced in Chapter 3. For a proportional reinsurance, the transformation $Y_{insurer} = c S$ is identical to a coinsurance adjustment in personal insurance. For stop-loss reinsurance, the transformation $Y_{reinsurer} = \max(0,S-M)$ is the same as an insurer's payment with a deductible $M$ and $Y_{insurer} = \min(S,M) = S \wedge M$ is equivalent to what a policyholder pays with deductible $M$. For practical applications of the mathematics, in personal insurance the focus is generally upon the expectation as this is a key ingredient used in pricing. In constrast, for reinsurance the focus is on the entire distribution of the risk, as the extreme events are a primary concern of the financial stability of the insurer and reinsurer.

This chapter describes the foundational and most basic of reinsurance treaties: Section 10.1 for proportional and Section 10.2 for non-proportional. Section 10.3 gives a flavor of more complex contracts.


### Proportional Reinsurance

The simplest example of a proportional treaty is called *quota share*.

-   In a quota share treaty, the reinsurer receives a flat percent, say 50%, of the premium for the book of business reinsured.

-   In exchange, the reinsurer pays 50% of losses, including allocated loss adjustment expenses

-   The reinsurer also pays the ceding company a ceding commission which is designed to reflect the differences in underwriting expenses incurred.
        
The amounts paid by the direct insurer and the reinsurer are summarized as

$$
Y_{insurer} = c S \ \ \text{and} \ \ \ Y_{reinsurer} = (1-c) S.
$$

Note that $Y_{insurer}+Y_{reinsurer}=S$.

**Example. Distribution of Losses under Quota Share**

To develop intuition for the effect of quota-share agreement on the distribution of losses, the following is a short `R` demonstration using simulation. Note the relative shapes of the distributions of total losses, the retained portion (of the insurer), and the reinsurer's portion.

```{r comment="", message=FALSE, echo=FALSE, fig.width=10, fig.height=4, fig.align='center'}
set.seed(2018)
theta = 1000
alpha = 3
nSim = 10000
library(actuar)
S <-  rpareto(nSim, shape = alpha, scale = theta)

par(mfrow=c(1,3))
plot(density(S), xlim=c(0,3*theta), main="Total Loss", xlab="Losses")
plot(density(0.75*S), xlim=c(0,3*theta), main="Insurer (75%)", xlab="Losses")
plot(density(0.25*S), xlim=c(0,3*theta), main="Reinsurer (25%)", xlab="Losses")
```


<h6 style="text-align: center;"><a id="displayQuotaShare" href="javascript:togglecode('toggleQuotaShare','displayQuotaShare');"><i><strong>Click Here to see the R Code</strong></i></a> </h6>
<div id="toggleQuotaShare" style="display: none">

```{r comment="", message=FALSE, eval=FALSE, fig.width=10, fig.height=4, fig.align='center'}
set.seed(2018)
theta = 1000
alpha = 3
nSim = 10000
library(actuar)
S <-  rpareto(nSim, shape = alpha, scale = theta)

par(mfrow=c(1,3))
plot(density(S), xlim=c(0,3*theta), main="Total Loss", xlab="Losses")
plot(density(0.75*S), xlim=c(0,3*theta), main="Insurer (75%)", xlab="Losses")
plot(density(0.25*S), xlim=c(0,3*theta), main="Reinsurer (25%)", xlab="Losses")
```


</div>

#### Quota Share is Desirable for Reinsurers

The quota share contract is particularly desirable for the reinsurer. To see this, suppose that an insurer and reinsurer wish to enter a contract to share total losses $S$ such that $$Y_{insurer}=g(S) \ \ \ \text{and} \ \ \ \ Y_{reinsurer}=S-g(S),$$
for some generic function $g(\cdot)$ (known as the *retention* function). Suppose further that the insurer only cares about the variability of retained claims and is indifferent to the choice of $g$ as long as $Var~Y_{insurer}$ stays the same and equals, say, $Q$. Then, the following result shows that the quota share reinsurance treaty minimizes the reinsurer's uncertainty as measured by $Var~Y_{reinsurer}$.

**Proposition**. Suppose that $Var~Y_{insurer}=Q.$ Then, $Var ((1-c)S) \le Var(g(S))$ for all $g(.)$.

<h6 style="text-align: center;"><a id="displayProof" href="javascript:togglecode('toggleProof','displayProof');"><i><strong>Click Here to see the Justification of the Proposition</strong></i></a> </h6>
<div id="toggleProof" style="display: none">

**Proof of the Proposition**. With $Y_{reinsurer} = S - Y_{insurer}$ and the law of total variation
$$
\begin{array}{ll}
Var (Y_{reinsurer}) &= Var (S-Y_{insurer}) \\
&= Var (S) + Var (Y_{insurer})  - 2 Cov (S,Y_{insurer}) \\
&=Var (S) + Q - 2 Corr (S,Y_{insurer}) \times \sqrt{Q} \sqrt{Var (S)}
\end{array}
$$
In this expression, we see that $Q$ and $Var(S)$ do not change with the choice of $g$. Thus, we can minimize $Var (Y_{reinsurer})$ by maximizing the correlation $Corr (S,Y_{insurer})$. If we use a quota share reinsurance agreement, then $Corr (S,Y_{insurer})=Corr (S,(1-c)S)=1$, the maximum possible correlation. This establishes the proposition.
<p style="text-align:right;">$\Box$`</p>
</div>

The proposition is intuitively appealing - with quota share insurance, the reinsurer shares the responsibility for very large claims in the tail of the distribution. This is in contrast to non-proportional agreements where reinsurers take responsibility for the very large claims.

#### Optimizing Quota Share Agreements for Insurers

Now assume $n$ risks in the porfolio, $X_1, \ldots, X_n,$ so that the portfolio sum is $S= X_1 + \cdots + X_n$. For simplicity, we focus on the case of independent risks. Let us consider a variation of the basic quota share agreement where the amount retained by the insurer may vary with each risk, say $c_i$. Thus, the insurer's portion of the portfolio risk is $Y_{insurer} = \sum_{i=1}^n c_i X_i$. What is the best choice of the proportions $c_i$?

To formalize this question, we seek to find those values of $c_i$ that minimize $Var  ~Y_{insurer}$ subject to the constraint that $E ~Y_{insurer} = K.$ The requirement that $E ~Y_{insurer} = K$ suggests that the insurers wishes to retain a revenue in at least the amount of the constant $K$. Subject to this revenue constraint, the insurer wishes to minimize uncertainty of the retained risks as measured by the variance.

<h6 style="text-align: center;"><a id="displayDerivationProof" href="javascript:togglecode('toggleDerivationProof','displayDerivationProof');"><i><strong>Click Here to see the Optimal Retention Proportions</strong></i></a> </h6>
<div id="toggleDerivationProof" style="display: none">

**The Optimal Retention Proportions**

Minimizing $Var ~Y_{insurer}$ subject to  $E ~Y_{insurer} = K$ is a constrained optimization problem - we can use the method of Lagrange multipliers, a calculus technique, to solve this. To this end, define the Lagrangian
$$
\begin{array}{ll}
L &= Var (Y_{insurer}) - \lambda (E ~Y_{insurer} - K) \\
&= \sum_{i=1}^n c_i^2 ~Var ~X_i - \lambda (\sum_{i=1}^n c_i ~E ~X_i - K) 
\end{array}
$$
Taking a partial derivative with respect to $\lambda$ and setting this equal simply means that the constraint, $E ~Y_{insurer} = K$, is enforced and we have to choose the proportions $c_i$ to satisfy this constraint. Moreover, taking the partial derivative with respect to each proportion $c_i$ yields
$$
\frac{\partial}{\partial c_i} L = 2 c_i ~Var~ X_i - \lambda ~E ~X_i = 0 
$$

so that

$$
c_i  =  \frac{\lambda}{2} \frac{E ~X_i}{Var ~X_i} .
$$
</div>

From the math, it turns out that the constant for the $i$th risk, $c_i$ is proportional to $\frac{E ~X_i}{Var ~X_i}$. This is intuitively appealing. Other things being equal, a higher revenue as measured by $E ~X_i$ means a higher value of $c_i$. In the same way, a higher value of uncertainty as measured by $Var ~X_i$ means a lower value of $c_i$. The proportional scaling factor is determined by the revenue requirement $E ~Y_{insurer} = K$.

The following example helps to develop a feel for this relationship.

<h6 style="text-align: center;"><a id="displayParetoRisksProp" href="javascript:togglecode('toggleParetoRisksProp','displayParetoRisksProp');"><i><strong>Click Here to see an Example with Three Pareto Risks</strong></i></a> </h6>
<div id="toggleParetoRisksProp" style="display: none">


**Example**. Consider three risks that have a Pareto distribution. The graph, and supporting code, give values of $c_1$, $c_2$, and $c_3$ for a required revenue $K$. Note that these values increase linearly with $K$.

```{r comment="", message=FALSE,  fig.width=8, fig.height=4, fig.align='center'}


theta1 = 1000;theta2 = 2000;theta3 = 3000;
alpha1 = 3;alpha2 = 3;alpha3 = 4;
library(actuar)
propnfct <- function(alpha,theta){
  mu    <- mpareto(shape=alpha, scale=theta, order=1)
  var   <- mpareto(shape=alpha, scale=theta, order=2) - mu^2
  ratio <- mu/var
  ratio
}
c1 <- propnfct(alpha1, theta1)
c2 <- propnfct(alpha2, theta2)
c3 <- propnfct(alpha3, theta3)
summeans = mpareto(shape=alpha1, scale=theta1, order=1)+
           mpareto(shape=alpha2, scale=theta2, order=1)+
           mpareto(shape=alpha3, scale=theta3, order=1)  
temp = c1*mpareto(shape=alpha1, scale=theta1, order=1)+
       c2*mpareto(shape=alpha2, scale=theta2, order=1)+
       c3*mpareto(shape=alpha3, scale=theta3, order=1)  
KVec = seq(100,summeans,length.out=20)
c1Vec <- c2Vec <-c3Vec <- 0*KVec 
for (j in 1:20) {
  c1Vec[j] = c1 * KVec[j]/temp
  c2Vec[j] = c2 * KVec[j]/temp
  c3Vec[j] = c3 * KVec[j]/temp
  }
plot(KVec,c1Vec, type="l", ylab="proportion", xlab="required revenue", ylim=c(0,1))
lines(KVec,c2Vec)
lines(KVec,c3Vec)
text(1200,.8,expression(c[1]))
text(2000,.75,expression(c[2]))
text(1500,.3,expression(c[3]))

```

</div>

### Non-Proportional Reinsurance

####The Optimality of Stop Loss Insurance

Under this arrangement, the insurer sets a retention level $M (>0)$ and pays in full total claims for which $S  \le M$. Thus, the insurer retains an amount $M$ of the risk. Further, for claims for which $S > M$, the direct insurer pays $M$ and the reinsurer pays the remaining amount $S-M$. Summarizing, the amounts paid by the direct insurer and the reinsurer are
    
$$
Y_{insurer} =
\begin{cases}
S & \text{for } S \le M\\
M & \text{for } S >M \\
\end{cases} \ \ \ \ = \min(S,M) = S \wedge M
$$

and

$$
Y_{reinsurer} =
\begin{cases}
0 & \text{for } S \le M\\
S- M &  \text{for } S >M \\
\end{cases} \ \ \ \  = \max(0,S-M) .
$$

As before, note that $Y_{insurer}+Y_{reinsurer}=S$.

The stop loss type of contract is particularly desirable for the insurer. Similar to earlier, suppose that an insurer and reinsurer wish to enter a contract so that $Y_{insurer}=g(S)$ and $Y_{reinsurer}=S-g(S)$ for some generic retention function $g(\cdot)$. Suppose further that the insurer only cares about the variability of retained claims and is indifferent to the choice of $g$ as long as $Var~Y_{insurer}$ can be minimized. Again, we impose the constraint that $E ~Y_{insurer} = K$; the insurer needs to retain a revenue $K$. Subject to this revenue constraint, the insurer wishes to minimize uncertainty of the retained risks (as measured by the variance). Then, the following result shows that the stop loss reinsurance treaty minimizes the reinsurer's uncertainty as measured by $Var~Y_{reinsurer}$.


**Proposition**. Suppose that $E~Y_{insurer}=K.$ Then, $Var (S \wedge M) \le Var(g(S))$ for all $g(.)$.

<h6 style="text-align: center;"><a id="displayProofStopLoss" href="javascript:togglecode('toggleProofStopLoss','displayProofStopLoss');"><i><strong>Click Here to see the Justification of the Proposition</strong></i></a> </h6>
<div id="toggleProofStopLoss" style="display: none">

**Proof of the Proposition**. Add and subtract a constant $M$ and expand the square to get
$$
\begin{array}{ll}
Var~ g(S) &= E (g(S) - K)^2 = E (g(S) -M +M- K)^2 \\
&= E (g(S) -M)^2 +  (M- K)^2 +2 E (g(S) -M)(M- K) \\
&= E (g(S) -M)^2 -  (M- K)^2 ,
\end{array}
$$
because $E ~g(S)= K.$

Now, for any retention function, we have $g(S) \le S$, that is, the insurer's retained claims are less than or equal to total claims. Using the notation $g_{SL}(S) = S \wedge M$ for stop loss insurance, we have

$$
\begin{array}{ll}
M- g_{SL}(S) &= M-(S \wedge M) \\
&= (M-S) \wedge 0 \\
&\le (M-g(S)) \wedge 0 .
\end{array}
$$
Squaring each side yields 
$$(M- g_{SL}(S))^2 \le (M-g(S))^2 \wedge 0 \le (M-g(S))^2.$$

Returning to our expression for the variance, we have
$$
\begin{array}{ll}
Var~ g_{SL}(S) &= E (g_{SL}(S) -M)^2 -  (M- K)^2 \\
&\le E (g_{SL}(S) -M)^2 -  (M- K)^2 = Var~ g(S) ,
\end{array}
$$
for any retention function $g$. This establishes the proposition.
<p style="text-align:right;">$\Box$`</p>

</div>

The proposition is intuitively appealing - with stop loss insurance, the reinsurer takes the responsibility for very large claims in the tail of the distribution, not the insurer. 

#### Excess of Loss

A closely related form of non-proportional reinsurance is the *excess of loss* coverage. Under this contract, we assume that the total risk $S$ can be thought of as composed as $n$ separate risks $X_1, \ldots, X_n$ and that each of these risks are subject to upper limit, say, $M_i$. So the insurer retains

$$
Y_{i,insurer} = X_i \wedge M_i \ \ \ \ Y_{insurer} = \sum_{i=1}^n Y_{i,insurer}
$$
and the reinsurer is responsible for the excess, $Y_{reinsurer}=S - Y_{insurer}$. The retention limits may vary by risk or may be the same for all risks, $M_i =M$, for all $i$.

####Optimal Choice for Excess of Loss Retention Limits

What is the best choice of the excess of loss retention limits $M_i$? To formalize this question, we seek to find those values of $M_i$ that minimize $Var  ~Y_{insurer}$ subject to the constraint that $E ~Y_{insurer} = K.$ Subject to this revenue constraint, the insurer wishes to minimize uncertainty of the retained risks (as measured by the variance).

<h6 style="text-align: center;"><a id="displayDerivationProofExcess" href="javascript:togglecode('toggleDerivationProofExcess','displayDerivationProofExcess');"><i><strong>Click Here to see the Optimal Retention Proportions</strong></i></a> </h6>
<div id="toggleDerivationProofExcess" style="display: none">

**The Optimal Retention Limits**

Minimizing $Var ~Y_{insurer}$ subject to  $E ~Y_{insurer} = K$ is a constrained optimization problem - we can use the method of Lagrange multipliers, a calculus technique, to solve this. As before, define the Lagrangian
$$
\begin{array}{ll}
L &= Var (Y_{insurer}) - \lambda (E ~Y_{insurer} - K) \\
&= \sum_{i=1}^n ~Var (X_i \wedge M_i) - \lambda (\sum_{i=1}^n ~E(X_i \wedge M_i)- K) 
\end{array}
$$

We first recall the relationships

$$
E~S \wedge M = \int_0^M ~(1- F(S))dx
$$
and

$$
E~(S \wedge M)^2 = 2\int_0^M ~x(1- F(x))dx
$$

Taking a partial derivative with respect to $\lambda$ and setting this equal simply means that the constraint, $E ~Y_{insurer} = K$, is enforced and we have to choose the limits $M_i$ to satisfy this constraint. Moreover, taking the partial derivative with respect to each limit $M_i$ yields

$$
\begin{array}{ll}
\frac{\partial}{\partial M_i} L 
&= \frac{\partial}{\partial M_i}  ~Var~ (X_i \wedge M_i)  - \lambda \frac{\partial}{\partial M_i} ~E ~(X_i \wedge M_i) \\
&= \frac{\partial}{\partial M_i} \left(E~ (X_i \wedge M_i)^2 -(E ~(X_i \wedge M_i))^2\right) - \lambda (1-F_i(M_i)) \\
&= 2 M_i (1-F_i(M_i)) - 2 E ~(X_i \wedge M_i) (1-F_i(M_i))-
\lambda (1-F_i(M_i)).
\end{array}
$$

Setting $\frac{\partial}{\partial M_i} L =0$ and solving for $\lambda$, we get

$$
\lambda = 2 (M_i - E ~(X_i \wedge M_i)) .
$$
</div>

From the math, it turns out that the retention limit less the expected insurer's claims, $M_i - E ~(X_i \wedge M_i)$, is the same for *all* risks. This is intuitively appealing, ....


<h6 style="text-align: center;"><a id="displayParetoRisksExcess" href="javascript:togglecode('toggleParetoRisksExcess','displayParetoRisksExcess');"><i><strong>Click Here to see an Example with Three Pareto Risks</strong></i></a> </h6>
<div id="toggleParetoRisksExcess" style="display: none">


**Example**. Consider three risks that have a Pareto distribution, each having a different set of parameters (so they are independent but non-identical). We first optimize the Lagrangian using the `R` package `alabama` for *Augmented Lagrangian Adaptive Barrier Minimization Algorithm*. Then, we show that the optimal retention limits $M_1$, $M_2$, and $M_3$ resulting retention limit minus expected insurer's claims, $M_i - E ~(X_i \wedge M_i)$, is the same for all risks, as we derived theoretically. Finally, we graphically compare the distribution of total risks to that retained by the insurer and by the reinsurer.


```{r comment="", message=FALSE, warning=FALSE, fig.width=8, fig.height=4, fig.align='center'}

theta1 = 1000;theta2 = 2000;theta3 = 3000;
alpha1 = 3;   alpha2 = 3;   alpha3 = 4;
Pmin <- 2000
library(actuar)
VarFct <- function(M){
  M1=M[1];M2=M[2];M3=M[3]
  mu1    <- levpareto(limit=M1,shape=alpha1, scale=theta1, order=1)
  var1   <- levpareto(limit=M1,shape=alpha1, scale=theta1, order=2)-mu1^2
  mu2    <- levpareto(limit=M2,shape=alpha2, scale=theta2, order=1)
  var2   <- levpareto(limit=M2,shape=alpha2, scale=theta2, order=2)-mu2^2
  mu3    <- levpareto(limit=M3,shape=alpha3, scale=theta3, order=1)
  var3   <- levpareto(limit=M3,shape=alpha3, scale=theta3, order=2)-mu3^2
  varFct <- var1 +var2+var3
  meanFct <- mu1+mu2+mu3
  c(meanFct,varFct)
  }
f <- function(M){VarFct(M)[2]}
h <- function(M){VarFct(M)[1] - Pmin}
library(alabama)
par0=rep(1000,3)
op <- auglag(par=par0,fn=f,hin=h,control.outer=list(trace=FALSE))
M1star = op$par[1];M2star = op$par[2];M3star = op$par[3]
M1star -levpareto(M1star,shape=alpha1, scale=theta1,order=1)
M2star -levpareto(M2star,shape=alpha2, scale=theta2,order=1)
M3star -levpareto(M3star,shape=alpha3, scale=theta3,order=1)

set.seed(2018)
nSim = 10000
library(actuar)
Y1 <- rpareto(nSim, shape = alpha1, scale = theta1)
Y2 <- rpareto(nSim, shape = alpha2, scale = theta2)
Y3 <- rpareto(nSim, shape = alpha3, scale = theta3)
YTotal <- Y1 + Y2 + Y3
Yinsur <-  pmin(Y1,M1star)+pmin(Y2,M2star)+pmin(Y3,M3star)
Yreinsur <- YTotal - Yinsur

par(mfrow=c(1,3))
plot(density(YTotal),   xlim=c(0,10000), main="Total Loss", xlab="Losses")
plot(density(Yinsur),   xlim=c(0,10000), main="Insurer",    xlab="Losses")
plot(density(Yreinsur), xlim=c(0,10000), main="Reinsurer",  xlab="Losses")
```

</div>


### Additional Reinsurance Treaties

#### Surplus Share Proportional Treaty

Another proportional treaty is known as *surplus share*; this type of contract is common in commercial property insurance.

-   A surplus share treaty allows the reinsured to limit its exposure on
    any one risk to a given amount (the *retained line*).

-   The reinsurer assumes a part of the risk in proportion to the amount
    that the insured value exceeds the retained line, up to a given
    limit (expressed as a multiple of the retained line, or number
    of lines).

-   For example, let the retained line be \$100,000 and let the given
    limit be 4 lines (\$400,000). Then, if $S$ is the loss, the
    reinsurer's portion is $\min(400000, (S-100000)_+)$.


#### Layers of Coverage

One can also extend non-proportional stop loss treaties by introducing additional parties to the contract. For example, instead of simply an insurer and reinsurer or an insurer and a policyholder, think about the situation with all three parties, a policyholder, insurer, and reinsurer, who agree on how to share a risk. More generally, we consider $k$ parties. If $k=4$, it could be an insurer and three different reinsurers.


**Example**

-   Suppose that there are $k=3$ parties. The first party is responsible for the first 100 of claims, the second responsible for claims from 100 to 3000, and the third responsible for claims above 3000.

-   If there are four claims in the amounts 50, 600, 1800 and 4000, then they would be allocated to the parties as follows:

  Layer               Claim 1   Claim 2   Claim 3   Claim 4  Total
  ------------------ --------- --------- --------- --------- -------
  (0, 100\]             50        100       100       100    350
  (100, 3000\]           0        500      1700      2900    5100
  (3000, $\infty$)       0         0         0       1000    1000
  Total                 50        600      1800      4000    6450


To handle the general situation with $k$ groups, partition the positive real line into $k$ intervals using the cut-points
$$0 = M_0 < M_1 < \cdots < M_{k-1} < M_k = \infty.$$

Note that the $j$th interval is $(M_{j-1}, M_j]$. Now let $Y_j$ be the amount of risk shared by the $j$th party. To illustrate, if a loss $x$ is such that $M_{j-1} <x \le M_j$, then
$$\left(\begin{array}{c}
    Y_1\\ Y_2 \\ \vdots \\ Y_j \\Y_{j+1} \\ \vdots \\Y_k
    \end{array}\right)
    =\left(\begin{array}{c}
    M_1-M_0 \\ M_2-M_1  \\ \vdots \\ x-M_{j-1}  \\ 0 \\ \vdots \\0
    \end{array}\right)$$

More succinctly, we can write
    $$Y_j = \min(S,M_j) - \min(S,M_{j-1}) .$$

With the expression $Y_j = \min(S,M_j) - \min(S,M_{j-1})$, we see that the $j$th party is responsible for claims in the interval  $(M_{j-1}, M_j].$ With this, it is easy to check that $S = Y_1 + Y_2 + \cdots + Y_k.$ As emphasized in the following example, we also remark that the parties need not be different.


**Example**
-   Suppose that a policyholder is responsible for the
        first 500 of claims and all claims in excess of 100,000. The
        insurer takes claims between 100 and 100,000.

-   Then, we would use $M_1 = 100$, $M_2 =100000$.

-   The policyholder is responsible for $Y_1 =\min(S,100)$ and
        $Y_3 = S - \min(S,100000) = \max(0, S-100000)$.


For additional reading, wee the Wisconsin Property Fund site for more info on layers of reinsurance,
    <https://sites.google.com/a/wisc.edu/local-government-property-insurance-fund/home/reinsurance>.
    

####Portfolio Management Example

Many other variations of the foundational contracts are possible. For one more illustration, consider the following.


```{r warning=FALSE, message=FALSE, comment="", echo=FALSE}
# For the gamma distributions, use
alpha1 <- 2;      theta1 <- 100
alpha2 <- 2;      theta2 <- 200
# For the Pareto distributions, use
alpha3 <- 2;      theta3 <- 1000
alpha4 <- 3;      theta4 <- 2000
# Deductibles
M1 <- 100
M2 <- 200
```

**Example.** You are the Chief Risk Officer of a telecommunications firm. Your firm has several property and liabililty risks; we will consider:

- $X_1$ - buildings, modeled using a gamma distribution with mean `r alpha1*theta1` and scale parameter `r theta1`.

- $X_2$ - motor vehicles, modeled using a gamma distribution with mean `r alpha2*theta2` and scale parameter `r theta2`.

- $X_3$ - directors and executive officers risk, modeled using a Pareto distribution with mean `r round(theta3/(alpha3-1),digits=8)` and scale parameter `r theta3`.

- $X_4$ - cyber risks, modeled using a Pareto distribution with mean `r theta4/(alpha4-1)` and scale parameter `r theta4`.

Denote the total risk as $$S = X_1 + X_2 + X_3 + X_4 .$$

For simplicity, you assume that these risks are independent. 

To manage the risk, you seek some insurance protection. You wish to manage internally small building and motor vehicles amounts, up to $M_1$ and $M_2$, respectively. You seek insurance to cover all other risks. Specifically, the insurer's portion is
$$ Y_{insurer} = (X_1 - M_1)_+ + (X_2 - M_2)_+ + X_3 + X_4 ,$$
so that your retained risk is $Y_{retained}= S- Y_{insurer} = \min(X_1,M_1) +  \min(X_2,M_2)$. Using deductibles $M_1=$ `r M1` and $M_2=$ `r M2`:

a. Determine the expected claim amount of (i) that retained, (ii) that accepted by the insurer, and (iii) the total overall amount.

b. Determine the 80th, 90th, 95th, and 99th percentiles for (i) that retained, (ii) that accepted by the insurer, and (iii) the total overall amount. 

c. Compare the distributions by plotting the densities for (i) that retained, (ii) that accepted by the insurer, and (iii) the total overall amount.


<h6 style="text-align: center;"><a id="displayPortMgtExample" href="javascript:togglecode('togglePortMgtExample','displayPortMgtExample');"><i><strong>R Code for Example Solution</strong></i></a> </h6>
<div id="togglePortMgtExample" style="display: none">

In preparation, here is the code needed to set the parameters.

```{r warning=FALSE, message=FALSE, comment="", eval=FALSE}
# For the gamma distributions, use
alpha1 <- 2;      theta1 <- 100
alpha2 <- 2;      theta2 <- 200
# For the Pareto distributions, use
alpha3 <- 2;      theta3 <- 1000
alpha4 <- 3;      theta4 <- 2000
# Limits
M1     <- 100
M2     <- 200
```

With these parameters, we can now simulate realizations of the portfolio risks.

```{r warning=FALSE, message=FALSE, fig.width=8, fig.height=4, fig.align='center', comment=""}
# Simulate the risks
nSim <- 10000  #number of simulations
set.seed(2017) #set seed to reproduce work 
X1 <- rgamma(nSim,alpha1,scale = theta1)  
X2 <- rgamma(nSim,alpha2,scale = theta2)  
# For the Pareto Distribution, use
library(actuar)
X3 <- rpareto(nSim,scale=theta3,shape=alpha3)
X4 <- rpareto(nSim,scale=theta4,shape=alpha4)
# Portfolio Risks
S         <- X1 + X2 + X3 + X4
Yretained <- pmin(X1,M1) + pmin(X2,M2)
Yinsurer  <- S - Yretained
```

**(a)** Here is the code for the expected claim amounts.

```{r warning=FALSE, message=FALSE, fig.width=8, fig.height=4, fig.align='center', comment=""}
# Expected Claim Amounts
ExpVec <- t(as.matrix(c(mean(Yretained),mean(Yinsurer),mean(S))))
colnames(ExpVec) <- c("Retained", "Insurer","Total")
round(ExpVec,digits=2)
```

**(b)** Here is the code for the quantiles.

```{r warning=FALSE, message=FALSE, fig.width=8, fig.height=4, fig.align='center', comment=""}
# Quantiles
quantMat <- rbind(
  quantile(Yretained, probs=c(0.80, 0.90, 0.95, 0.99)),
  quantile(Yinsurer,  probs=c(0.80, 0.90, 0.95, 0.99)),
  quantile(S       ,  probs=c(0.80, 0.90, 0.95, 0.99)))
rownames(quantMat) <- c("Retained", "Insurer","Total")
round(quantMat,digits=2)
```

**(c)** Here is the code for the density plots of the retained, insurer, and total portfolio risk.

```{r warning=FALSE, message=FALSE, fig.width=8, fig.height=4, fig.align='center', comment=""}

par(mfrow=c(1,3))
plot(density(Yretained), xlim=c(0,500), main="Retained Portfolio Risk", xlab="Loss (Note the different horizontal scale)")
plot(density(Yinsurer), xlim=c(0,15000), main="Insurer Portfolio Risk", xlab="Loss")
plot(density(S), xlim=c(0,15000), main="Total Portfolio Risk", xlab="Loss")
```

</div>

```{js echo=FALSE}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show";}
      else {ele.style.display = "block"; text.innerHTML = "Hide";}}
```
